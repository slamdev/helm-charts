initContainer:
  enabled: true
  image:
    # initContainer.image.repository -- initContainer image repository
    repository: alpine
    # initContainer.image.tag -- initContainer image tag
    tag: 3.19.1
    # initContainer.image.pullPolicy -- initContainer image pull policy
    pullPolicy: IfNotPresent
  command: "apk add perl && cp /opt/envoy.yaml.tpl /config/envoy.yaml && perl -pi -e 's/ENV_([_A-Z0-9]+)_ENV/$ENV{$1}/g' /config/envoy.yaml"

# replicaCount -- number of replicas for haproxy deployment.
replicaCount: 1

image:
  # image.repository -- image repository
  repository: envoyproxy/envoy
  # image.tag -- image tag (chart's appVersion value will be used if not set)
  tag: ""
  # image.pullPolicy -- image pull policy
  pullPolicy: IfNotPresent

# imagePullSecrets -- image pull secret for private images
imagePullSecrets: []
# nameOverride -- override name of the chart
nameOverride: ""
# fullnameOverride -- full name of the chart.
fullnameOverride: ""

serviceAccount:
  # serviceAccount.create -- specifies whether a service account should be created
  create: false
  # serviceAccount.annotations -- annotations to add to the service account
  annotations: {}
  # serviceAccount.name -- the name of the service account to use; if not set and create is true, a name is generated using the fullname template
  name:

# podSecurityContext -- specifies security settings for a pod
podSecurityContext: {}
# fsGroup: 2000

service:
  # service.type -- service type
  type: ClusterIP
  # service.ports -- list of service ports
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  # service.loadBalancerIP -- IP of service load balancer
  loadBalancerIP: ""
  # service.annotations -- annotations to add to the service
  annotations: {}

serviceAdmin:
  # serviceAdmin.port -- port of envoy admin service
  port: 80

ingress:
  # ingress.enabled -- enables Ingress for envoy
  enabled: false
  # ingress.annotations -- ingress annotations
  annotations: {}
  # kubernetes.io/ingress.class: envoy
  # kubernetes.io/tls-acme: "true"
  # ingress.hosts -- ingress accepted hostnames
  hosts: []
  #  - host: chart-example.local
  #    paths: []
  # ingress.tls -- ingress TLS configuration
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# resources -- custom resource configuration
resources: {}
# limits:
#   cpu: 100m
#   memory: 128Mi
# requests:
#   cpu: 100m
#   memory: 128Mi

# nodeSelector -- node for scheduler pod assignment
nodeSelector: {}

# tolerations -- tolerations for scheduler pod assignment
tolerations: []

# affinity -- affinity for scheduler pod assignment
affinity: {}

# volumeMounts -- volume mounts
volumeMounts:
#  - name: data
#    mountPath: /envoy-data

# volumes -- volumes
volumes:
#  - name: data
#    emptyDir: {}

# secret -- secret
secret:
  # type: Opaque
  # data: {}
  # stringData: {}

# env -- environment variables for the deployment
env:
#  - name: NODE_LABEL_REGION
#    value: "failure-domain.beta.kubernetes.io/region"
#  - name: NODE_LABEL_INSTANCE_TYPE
#    value: "beta.kubernetes.io/instance-type"

# args -- extra args to pass to container
args: []

serviceMonitor:
  # serviceMonitor.enabled -- ServiceMonitor CRD is created for a prometheus operator
  enabled: false
  # serviceMonitor.additionalLabels -- additional labels for service monitor
  additionalLabels: {}

livenessProbe:
  httpGet:
    # livenessProbe.httpGet.path -- path for liveness probe
    path: /ready
    # livenessProbe.httpGet.port -- port for liveness probe
    port: http-admin

readinessProbe:
  httpGet:
    # readinessProbe.httpGet.path -- path for readiness probe
    path: /ready
    # readinessProbe.httpGet.port -- port for readiness probe
    port: http-admin

# containerPorts -- list of container ports, should match static port_value 's from config.yaml
containerPorts:
  - name: http
    containerPort: 10000
    protocol: TCP

# containerPort -- container port, should match admin port_value from config.yaml
containerAdminPort: 9901

# additionalResources -- list of additional resources to create (are processed via `tpl` function)
additionalResources: []
# - |
#   apiVersion: v1
#   kind: ConfigMap
#   metadata:
#     name: {{ include "envoy.fullname" . }}-cm
#     namespace: {{ .Release.Namespace }}
#
# - |
#    apiVersion: v1
#    kind: Secret
#    metadata:
#      name: {{ include "envoy.fullname" . }}-s
#      namespace: {{ .Release.Namespace }}
#    stringData:
#      mykey: my-value

# configYaml -- config yaml
configYaml: |-
  admin:
    access_log_path: /tmp/admin_access.log
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 9901
  static_resources:
    listeners:
    - name: listener_0
      address:
        socket_address:
          protocol: TCP
          address: 0.0.0.0
          port_value: 10000
      filter_chains:
      - filters:
        - name: envoy.filters.network.http_connection_manager
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
            stat_prefix: ingress_http
            access_log:
            - name: envoy.access_loggers.file
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                # For the demo config in the Docker container we use:
                #   - system logs -> `/dev/stderr`
                #   - (listener) access_logs -> `/dev/stdout`
                path: /dev/stdout
            route_config:
              name: local_route
              virtual_hosts:
              - name: local_service
                domains: ["*"]
                routes:
                - match:
                    prefix: "/"
                  route:
                    host_rewrite_literal: www.envoyproxy.io
                    cluster: service_envoyproxy_io
            http_filters:
            - name: envoy.filters.http.router
    clusters:
    - name: service_envoyproxy_io
      connect_timeout: 30s
      type: LOGICAL_DNS
      # Comment out the following line to test on v6 networks
      dns_lookup_family: V4_ONLY
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: service_envoyproxy_io
        endpoints:
        - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: www.envoyproxy.io
                  port_value: 443
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          sni: www.envoyproxy.io
